{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "### Code\n",
    "Feel free to comment on style, library usage, or other improvements.\n",
    "### Methodology\n",
    "Feel free to comment on the student's data setup, modeling methodology, and model evaluation.\n",
    "### Conceptual Understanding\n",
    "Finally, feel free to add any suggestions or takeaways on how the student could continue to improve their understanding of these concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "# Student-sample-1.py #\n",
    "#---------------------#\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "##--------------------------------------------------------##\n",
    "## I am guessing the idea here is try to predict the \n",
    "## employee salary given location/title/contractType/ect...\n",
    "##--------------------------------------------------------##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## from sklearn import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Load data\n",
    "d = pd.read_csv('../data/data.train.csv')\n",
    "## unless file has been renamed... file name is wrong!\n",
    "## d is a bit too generic. Try to be a bit descriptive when defining variables\n",
    "\n",
    "## Perform some Exploratory Data Analysis before jumping into predictions/modeling and so on.\n",
    "## Remember: without some EDA/pre-processing/feature engineering... even the best ML models might perform poorly\n",
    "## Check for nulls/NaNs... outliers... dataTypes... plot them... \n",
    "## visualize them even in pairplot maybe... try to make sense of the data and understand them ;)\n",
    "\n",
    "# Setup data for prediction\n",
    "x1 = data.SalaryNormalized\n",
    "## Is the loaded csv DataFrame named data or d... I'm confused! ;)\n",
    "x2 = pd.get_dummies(data.ContractType)\n",
    "\n",
    "## There is some confusion here :)\n",
    "## First: try to stick to the notations we taught in the classes:\n",
    "    ## X -> feature_matrix\n",
    "    ## y -> target_variable\n",
    "## Second: in your code you're creating a new 2D-DataFrame with the encoded full_time/part_time feature.\n",
    "## Hot-encoding is a great idea indeed, but then you have to:\n",
    "    ## add to the original DataFrame the encoded cols: e.g. using the join function ==> df = df.join(encodedDataFrame)\n",
    "    ## remove the column with categorical data from the original df ==> df = df.drop('ContractType',axis = 1)\n",
    "\n",
    "    \n",
    "# Setup model\n",
    "model = LinearRegression()\n",
    "## LinearRegression is often a good choice as a starting model.\n",
    "    ## Though, try to think about its pitfalls and how you would overcome them!\n",
    "    ## How about other models like Logistic Regression and/or Regression Tree?\n",
    "\n",
    "## Some more confusion here :)\n",
    "## You built the feature matrix... built the model... and finally evaluated the model...\n",
    "## What's missing?? You did not train the model ;)\n",
    "## Always remember: Get the data -> clean the data -> analyse the data -> \n",
    "    ## -> build the model -> train/test the model -> evaluate the model -> tune model params -> evaluate again...\n",
    "## It might be useful to write these steps down and look at them in order not to forget any important step!! ;)\n",
    "    \n",
    "# Evaluate model\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "## Modules should be imported at the beginning...\n",
    "\n",
    "scores = cross_val_score(model, x2, x1, cv=1, scoring='mean_absolute_error')\n",
    "## Following from before... (x2, x1) => (X, y) according to our notations.\n",
    "## The value of K in cross validation cannot be <= 1 since k-fold cross validation requires \n",
    "    ## at least one train/test split by setting n_folds=2 or more!\n",
    "## Any specific reason why you did you use mean_absolute_error and not others? E.g. how about R-squared?\n",
    "    ## Always remember what you trying to achieve and how you evaluating the model...\n",
    "    ## Depending on the application certain errors have to be penalized more or less...\n",
    "\n",
    "## Remember: data must be split into train/test... and use the test set only to evaluate the model...\n",
    "## Including any info about the test set within your analysis is like cheating LOL!\n",
    "## Warnings are nothing crucial. But try to read them and get rid of them. Certain functions/names etc might \n",
    "    ## indeed change in future versions of the libraries... and warnings are a way of communication between us and\n",
    "    ## the developers! In this case: Scoring method mean_absolute_error was renamed to \n",
    "    ## neg_mean_absolute_error in version 0.18\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "# Student-sample-2.py #\n",
    "#---------------------#\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "## file name is: part-2-data.train.csv\n",
    "\n",
    "# Setup data for prediction\n",
    "y = data.SalaryNormalized\n",
    "X = pd.get_dummies(data.ContractType)\n",
    "## Good naming convention :) and nice idea to hot encode categorical values..\n",
    "## How about the other categorical features though?? Why have they not been transformed?\n",
    "## Hotcoding is a great idea indeed, but then you have to:\n",
    "    ## add to the original DataFrame the encoded cols: e.g. using the join function ==> df = df.join(encodedDataFrame)\n",
    "    ## remove column with categorical data from the original df ==> df = df.drop('ContractType',axis = 1)\n",
    "    ## Rename X = df where df is the full feature matrix.\n",
    "\n",
    "## Perform some Exploratory Data Analysis before jumping into predictions/modeling and so on.\n",
    "## Remember: w/o some EDA/pre-processing/feature engineering... even the best ML models might perform poorly\n",
    "## Check for nulls/NaNs... outliers... dataTypes... plot them... \n",
    "## visualize them even in pairplot maybe... try to make sense of the data and understand them ;)\n",
    "    \n",
    "# Setup model\n",
    "model = LinearRegression()\n",
    "## model (as a name) is a bit generic. Here is fine since we only have one model..\n",
    "    ## But in other scenarios you might train multiple models. A self-explanatory name would be clearer \n",
    "    ## and make the code more readable for everyone ;)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='mean_absolute_error')\n",
    "## Any specific reason why you did you use mean_absolute_error and not others? \n",
    "    ## Always remember what you trying to achieve and how you evaluating the model...\n",
    "    ## Depending on the application certain errors have to be penalized more or less...\n",
    "## Warnings are nothing crucial. But try to read them and get rid of them. Certain functions/names etc might \n",
    "    ## indeed change in future versions of the libraries... and warnings are a way of communication between us and\n",
    "    ## the developers! In this case: Scoring method mean_absolute_error was renamed to \n",
    "    ## neg_mean_absolute_error in version 0.18\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##-----------------##\n",
    "## OVERALL REMARKS ##\n",
    "##-----------------##\n",
    "\n",
    "## Always check that your code runs w/o errors before submitting it...\n",
    "## To check if your code satisfies style requirements you can submit it online in different websites:\n",
    "    ## e.g. http://pep8online.com/ \n",
    "    ## or run pylint: e.g. pylint mymodule.py\n",
    "## Good style. One remark only: try to write few comments to explain the decisions you made to use a specific model \n",
    "    ## or technique instead of others. It will help your colleagues to understand the code, but also yourself,\n",
    "    ## when looking at your code you might not remember why certain decision were taken at that time ;)\n",
    "## Did you try to add / combine / refine features? If yes, did it increase the model prective power? \n",
    "    ## If not, give it a go! :)\n",
    "## Try also to fit other models to the same dataset... train/test/evaluate them... but \n",
    "    ## especially compare them! You will get a better feeling of their pros&cons.\n",
    "## If any comment is not clear, just come and ask for more explanation :)\n",
    "## In general well done! ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
